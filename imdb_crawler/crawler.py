#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
IMDBä¸»çˆ¬è™«ç±»
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€çš„çˆ¬è™«æ¥å£
"""

import os
import logging
from tqdm import tqdm
import random
import time

from .config import IMDBConfig
from .network import IMDBNetworkManager
from .parser import IMDBPageParser
from .data_processor import IMDBDataProcessor


class IMDBMovieCrawler:
    """IMDBç”µå½±çˆ¬è™«ä¸»ç±»"""
    
    def __init__(self, config=None):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.config = config or IMDBConfig()
        self.network_manager = IMDBNetworkManager()
        self.parser = IMDBPageParser()
        self.data_processor = IMDBDataProcessor()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if not os.path.exists(self.config.OUTPUT_DIR):
            os.makedirs(self.config.OUTPUT_DIR)
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        self.logger.info("IMDBç”µå½±çˆ¬è™«åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        log_config = self.config.LOG_CONFIG
        logging.basicConfig(
            level=getattr(logging, log_config['level']),
            format=log_config['format'],
            handlers=[
                logging.FileHandler(log_config['file'], encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def crawl_movies(self, categories=None, max_movies=None, max_pages=5):
        """
        åˆ†æ‰¹çˆ¬å–IMDBç”µå½±æ•°æ® - æ”¶é›†ä¸€æ‰¹é“¾æ¥ï¼Œè§£æå®Œæ¯•åå†æ”¶é›†ä¸‹ä¸€æ‰¹
        
        Args:
            categories: è¦çˆ¬å–çš„åˆ†ç±»åˆ—è¡¨ï¼Œé»˜è®¤['top250']
            max_movies: æœ€å¤§çˆ¬å–ç”µå½±æ•°é‡ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®å€¼
            max_pages: æ¯ä¸ªåˆ†ç±»æœ€å¤§é¡µæ•°ï¼Œé»˜è®¤5
            
        Returns:
            dict: çˆ¬å–ç»“æœä¿¡æ¯
        """
        categories = categories or ['top250']
        max_movies = max_movies or self.config.MAX_MOVIES
        
        self.logger.info(f"å¼€å§‹åˆ†æ‰¹çˆ¬å–IMDBç”µå½±æ•°æ® - åˆ†ç±»: {categories}, ç›®æ ‡æ•°é‡: {max_movies}")
        
        try:
            all_movie_data = []
            collected_links = set()  # é¿å…é‡å¤é“¾æ¥
            batch_size = 50  # æ¯æ‰¹æ”¶é›†50ä¸ªé“¾æ¥
            batch_count = 0
            
            while len(all_movie_data) < max_movies:
                batch_count += 1
                remaining = max_movies - len(all_movie_data)
                target_batch_links = min(batch_size, remaining * 2)  # æ¯æ‰¹æ”¶é›†çš„é“¾æ¥æ•°
                
                self.logger.info(f"=== ç¬¬ {batch_count} æ‰¹IMDBçˆ¬å– ===")
                self.logger.info(f"å·²è·å–: {len(all_movie_data)} éƒ¨ç”µå½±ï¼Œè¿˜éœ€: {remaining} éƒ¨")
                
                # é˜¶æ®µ1ï¼šæ”¶é›†ä¸€æ‰¹æ–°çš„ç”µå½±é“¾æ¥ï¼ˆä¸é‡å¤ï¼‰
                self.logger.info(f"é˜¶æ®µ1: æ”¶é›† {target_batch_links} ä¸ªIMDBç”µå½±é“¾æ¥...")
                new_links = self._collect_batch_links(categories, target_batch_links, collected_links, max_pages)
                
                if not new_links:
                    self.logger.warning("æ— æ³•æ”¶é›†åˆ°æ›´å¤šIMDBç”µå½±é“¾æ¥ï¼Œçˆ¬å–ç»“æŸ")
                    break
                
                collected_links.update(new_links)
                self.logger.info(f"âœ“ é“¾æ¥æ”¶é›†å®Œæˆï¼æœ¬æ‰¹æ”¶é›† {len(new_links)} ä¸ªæ–°é“¾æ¥")
                
                # é˜¶æ®µ2ï¼šå®Œå…¨è§£æè¿™æ‰¹ç”µå½±ï¼ˆç›´åˆ°å®Œæˆæˆ–å¤±è´¥ï¼‰
                self.logger.info(f"é˜¶æ®µ2: å¼€å§‹è§£ææœ¬æ‰¹ {len(new_links)} ä¸ªIMDBç”µå½±...")
                batch_movies = self._parse_batch_movies(list(new_links), remaining)
                
                if batch_movies:
                    all_movie_data.extend(batch_movies)
                    self.logger.info(f"âœ“ æœ¬æ‰¹è§£æå®Œæˆï¼è·å– {len(batch_movies)} éƒ¨ç”µå½±ï¼Œæ€»è®¡: {len(all_movie_data)}/{max_movies}")
                else:
                    self.logger.warning(f"âœ— æœ¬æ‰¹é“¾æ¥è§£æå¤±è´¥ï¼Œè·³è¿‡ç»§ç»­ä¸‹ä¸€æ‰¹")
                
                # å¦‚æœå·²è¾¾åˆ°ç›®æ ‡ï¼Œåœæ­¢
                if len(all_movie_data) >= max_movies:
                    self.logger.info(f"ğŸ‰ å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {max_movies}ï¼Œçˆ¬å–ä»»åŠ¡å®Œæˆï¼")
                    break
                
                # æ‰¹æ¬¡é—´ä¼‘æ¯
                self.logger.info("æ‰¹æ¬¡é—´ä¼‘æ¯ 5-10 ç§’...")
                time.sleep(random.uniform(5, 10))
            
            # æ•°æ®æ¸…æ´—å’Œæœ€ç»ˆä¿å­˜
            if all_movie_data:
                # é™åˆ¶åˆ°ç›®æ ‡æ•°é‡
                final_movies = all_movie_data[:max_movies]
                cleaned_data = self.data_processor.clean_movie_data(final_movies)
                saved_files = self.data_processor.save_processed_data(
                    cleaned_data, 
                    self.config.OUTPUT_DIR
                )
                
                self.logger.info(f"IMDBçˆ¬è™«ä»»åŠ¡å®Œæˆï¼æœ€ç»ˆè·å– {len(cleaned_data)} éƒ¨ç”µå½±ä¿¡æ¯")
                
                return {
                    'success': True,
                    'data_count': len(cleaned_data),
                    'file_paths': saved_files,
                    'message': f'æˆåŠŸçˆ¬å– {len(cleaned_data)} éƒ¨IMDBç”µå½±'
                }
            else:
                return {
                    'success': False,
                    'data_count': 0,
                    'file_paths': {},
                    'message': 'æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆIMDBç”µå½±æ•°æ®'
                }
            
        except Exception as e:
            self.logger.error(f"IMDBçˆ¬è™«è¿è¡Œå‡ºé”™: {e}")
            return {
                'success': False,
                'data_count': 0,
                'file_paths': {},
                'message': f'IMDBçˆ¬å–å¤±è´¥: {str(e)}'
            }
        finally:
            self.network_manager.close()
    
    def _collect_batch_links(self, categories, target_count, exclude_links, max_pages):
        """æ”¶é›†ä¸€æ‰¹æ–°çš„IMDBç”µå½±é“¾æ¥ï¼ˆé¿å…é‡å¤ï¼‰"""
        new_links = []
        
        for category in categories:
            if len(new_links) >= target_count:
                break
            
            self.logger.info(f"ä»IMDBåˆ†ç±» '{category}' æ”¶é›†é“¾æ¥...")
            category_urls = self.config.get_movie_list_urls([category], max_pages)
            
            for i, url in enumerate(tqdm(category_urls, desc=f"è§£æIMDB{category}åˆ—è¡¨é¡µ", leave=False)):
                if len(new_links) >= target_count:
                    self.logger.info(f"å·²æ”¶é›†è¶³å¤ŸIMDBé“¾æ¥ ({len(new_links)}ä¸ª)ï¼Œåœæ­¢æ­¤åˆ†ç±»")
                    break
                
                try:
                    # å»¶æ—¶
                    if i > 0:
                        time.sleep(random.uniform(2, 4))
                    
                    # IMDBå®Œå…¨ä½¿ç”¨Seleniumï¼Œrequestsæ€»æ˜¯è¢«æ‹¦æˆª
                    response = self.network_manager.get_page(url, use_selenium=True)
                    
                    # ç¡®å®šURLç±»å‹
                    if 'chart' in url:
                        url_type = 'chart'
                    elif 'search' in url:
                        url_type = 'search'
                    else:
                        url_type = 'chart'
                    
                    # è§£æç”µå½±é“¾æ¥
                    movie_links = self.parser.parse_movie_list(response, url_type)
                    
                    # è¿‡æ»¤å·²æ”¶é›†çš„é“¾æ¥
                    filtered_links = [link for link in movie_links if link not in exclude_links]
                    new_links.extend(filtered_links)
                    
                    if filtered_links:
                        self.logger.info(f"ä»IMDBé¡µé¢è·å– {len(filtered_links)} ä¸ªæ–°é“¾æ¥ï¼Œç´¯è®¡: {len(new_links)}")
                    else:
                        self.logger.warning(f"IMDBé¡µé¢æ— æ–°é“¾æ¥: {url}")
                    
                except Exception as e:
                    self.logger.warning(f"è§£æIMDBåˆ—è¡¨é¡µé¢å¤±è´¥: {url}, é”™è¯¯: {e}")
                    continue
        
        # å»é‡å¹¶è¿”å›éœ€è¦çš„æ•°é‡
        unique_links = list(set(new_links))[:target_count]
        self.logger.info(f"IMDBæ‰¹æ¬¡é“¾æ¥æ”¶é›†å®Œæˆ - è·å¾— {len(unique_links)} ä¸ªæ–°é“¾æ¥")
        return unique_links
    
    def _parse_batch_movies(self, movie_links, max_count):
        """è§£æä¸€æ‰¹IMDBç”µå½±è¯¦æƒ…"""
        self.logger.info(f"å¼€å§‹è§£æ {len(movie_links)} ä¸ªIMDBç”µå½±è¯¦æƒ…ï¼ˆæœ€å¤š {max_count} éƒ¨ï¼‰")
        movie_data = []
        
        for i, link in enumerate(tqdm(movie_links, desc="è§£æIMDBç”µå½±è¯¦æƒ…", leave=False)):
            if len(movie_data) >= max_count:
                self.logger.info(f"å·²è¾¾åˆ°æ‰¹æ¬¡ç›®æ ‡ {max_count}ï¼Œåœæ­¢è§£æ")
                break
            
            try:
                # å»¶æ—¶
                time.sleep(random.uniform(
                    self.config.DELAY_MIN,
                    self.config.DELAY_MAX
                ))
                
                # IMDBå®Œå…¨ä½¿ç”¨Seleniumï¼Œrequestsè¢«æ‹¦æˆª
                response = self.network_manager.get_page(link, use_selenium=True)
                movie_info = self.parser.parse_movie_detail(response, link)
                
                if movie_info and movie_info.get('title'):
                    movie_data.append(movie_info)
                    self.logger.info(f"âœ“ IMDBè§£ææˆåŠŸ: {movie_info.get('title')} ({len(movie_data)}/{max_count})")
                else:
                    self.logger.warning(f"âœ— IMDBç”µå½±ä¿¡æ¯ä¸å®Œæ•´: {link}")
                
            except Exception as e:
                self.logger.warning(f"âœ— è§£æIMDBç”µå½±è¯¦æƒ…å¤±è´¥: {link}, é”™è¯¯: {e}")
                continue
        
        self.logger.info(f"IMDBæ‰¹æ¬¡è§£æå®Œæˆ - æˆåŠŸè·å– {len(movie_data)} éƒ¨ç”µå½±")
        return movie_data

    def _collect_sufficient_links(self, categories, target_count, max_pages):
        """æ”¶é›†è¶³å¤Ÿæ•°é‡çš„IMDBç”µå½±é“¾æ¥"""
        all_movie_links = []
        
        for category in categories:
            if len(all_movie_links) >= target_count * 2:  # æ”¶é›†è¶³å¤Ÿçš„é“¾æ¥ååœæ­¢
                self.logger.info(f"å·²æ”¶é›†è¶³å¤ŸIMDBé“¾æ¥ ({len(all_movie_links)}ä¸ª)ï¼Œåœæ­¢è§£æåˆ—è¡¨é¡µé¢")
                break
            
            self.logger.info(f"å¼€å§‹æ”¶é›†IMDBåˆ†ç±» '{category}' çš„ç”µå½±é“¾æ¥")
            category_urls = self.config.get_movie_list_urls([category], max_pages)
            
            for i, url in enumerate(tqdm(category_urls, desc=f"è§£æIMDB{category}åˆ—è¡¨é¡µ")):
                if len(all_movie_links) >= target_count * 2:  # è¾¾åˆ°ç›®æ ‡åç«‹å³åœæ­¢
                    self.logger.info(f"å·²æ”¶é›†åˆ° {len(all_movie_links)} ä¸ªIMDBé“¾æ¥ï¼Œåœæ­¢è§£ææ›´å¤šåˆ—è¡¨é¡µ")
                    break
                
                try:
                    # åˆ—è¡¨é¡µé¢å»¶æ—¶
                    if i > 0:
                        time.sleep(random.uniform(1, 3))
                    
                    # IMDBå®Œå…¨ä½¿ç”¨Selenium
                    response = self.network_manager.get_page(url, use_selenium=True)
                    
                    # ç¡®å®šURLç±»å‹
                    if 'chart' in url:
                        url_type = 'chart'
                    elif 'search' in url:
                        url_type = 'search'
                    else:
                        url_type = 'chart'
                    
                    # è§£æç”µå½±é“¾æ¥
                    movie_links = self.parser.parse_movie_list(response, url_type)
                    
                    if len(movie_links) > 0:
                        all_movie_links.extend(movie_links)
                        self.logger.info(f"ä»IMDBé¡µé¢è·å– {len(movie_links)} ä¸ªé“¾æ¥ï¼Œæ€»è®¡: {len(all_movie_links)}")
                    else:
                        self.logger.warning(f"IMDBé¡µé¢æ— é“¾æ¥ï¼Œå¯èƒ½è¢«åçˆ¬è™«æ‹¦æˆª: {url}")
                        # è¿ç»­å¤±è´¥æ—¶å¢åŠ å»¶æ—¶
                        time.sleep(random.uniform(5, 10))
                
                except Exception as e:
                    self.logger.warning(f"è§£æIMDBåˆ—è¡¨é¡µé¢å¤±è´¥: {url}, é”™è¯¯: {e}")
                    continue
        
        # å»é‡
        unique_links = list(set(all_movie_links))
        self.logger.info(f"IMDBé“¾æ¥æ”¶é›†é˜¶æ®µå®Œæˆ - æ€»é“¾æ¥æ•°: {len(unique_links)}")
        
        return unique_links
    
    def _crawl_movie_details_with_limit(self, movie_links, max_movies):
        """çˆ¬å–IMDBç”µå½±è¯¦æƒ…ï¼ˆå¸¦æ•°é‡é™åˆ¶ï¼‰"""
        movie_data = []
        selenium_failures = 0
        
        for i, link in enumerate(tqdm(movie_links, desc="çˆ¬å–IMDBç”µå½±è¯¦æƒ…")):
            if len(movie_data) >= max_movies:
                self.logger.info(f"å·²è¾¾åˆ°IMDBç›®æ ‡æ•°é‡ {max_movies}ï¼Œåœæ­¢çˆ¬å–è¯¦æƒ…")
                break
            
            try:
                # è¯¦æƒ…é¡µå»¶æ—¶
                time.sleep(random.uniform(
                    self.config.DELAY_MIN,
                    self.config.DELAY_MAX
                ))
                
                # IMDBå®Œå…¨ä½¿ç”¨Seleniumï¼Œrequestsè¢«æ‹¦æˆª
                response = self.network_manager.get_page(link, use_selenium=True)
                movie_info = self.parser.parse_movie_detail(response, link)
                
                if movie_info and movie_info.get('title'):
                    movie_data.append(movie_info)
                    self.logger.info(f"æˆåŠŸçˆ¬å–IMDB: {movie_info.get('title')} ({len(movie_data)}/{max_movies})")
                else:
                    self.logger.warning(f"IMDBç”µå½±ä¿¡æ¯è§£æå¤±è´¥: {link}")
                
            except Exception as e:
                self.logger.warning(f"çˆ¬å–IMDBç”µå½±è¯¦æƒ…å¤±è´¥: {link}, é”™è¯¯: {e}")
                continue
        
        self.logger.info(f"IMDBè¯¦æƒ…çˆ¬å–å®Œæˆ - æˆåŠŸè·å– {len(movie_data)} éƒ¨ç”µå½±")
        return movie_data

    def _is_movie_info_complete(self, movie_info):
        """æ£€æŸ¥ç”µå½±ä¿¡æ¯æ˜¯å¦å®Œæ•´ - æ”¾å®½æ ‡å‡†"""
        if not movie_info:
            return False
        
        # è‡³å°‘éœ€è¦æœ‰æ ‡é¢˜æˆ–IDä¹‹ä¸€
        has_title = bool(movie_info.get('title', '').strip())
        has_id = bool(movie_info.get('imdb_id', '').strip())
        
        if not has_title and not has_id:
            return False
        
        # å¦‚æœæœ‰åŸºæœ¬ä¿¡æ¯ï¼Œå°±è®¤ä¸ºæ˜¯å®Œæ•´çš„
        # è¯„åˆ†å¯èƒ½ä¸ºNoneæˆ–0ï¼Œè¿™æ˜¯æ­£å¸¸çš„
        return True
    
    def get_movie_by_id(self, imdb_id):
        """æ ¹æ®IMDB IDè·å–å•ä¸ªç”µå½±ä¿¡æ¯"""
        url = f"{self.config.BASE_URL}/title/{imdb_id}/"
        
        try:
            response = self.network_manager.get_page(url, use_selenium=True)
            movie_info = self.parser.parse_movie_detail(response, url)
            
            if movie_info:
                cleaned_data = self.data_processor.clean_movie_data([movie_info])
                return cleaned_data[0] if cleaned_data else None
            
        except Exception as e:
            self.logger.error(f"è·å–IMDBç”µå½±ä¿¡æ¯å¤±è´¥ (ID: {imdb_id}): {e}")
            
        return None
    
    def search_movies(self, keyword, max_results=20):
        """æœç´¢ç”µå½±"""
        search_url = f"{self.config.BASE_URL}/find?q={keyword}&s=tt&ttype=ft"
        
        try:
            response = self.network_manager.get_page(search_url, use_selenium=True)
            movie_links = self.parser.parse_movie_list(response, 'search')
            
            # é™åˆ¶ç»“æœæ•°é‡
            if len(movie_links) > max_results:
                movie_links = movie_links[:max_results]
            
            # è·å–ç”µå½±è¯¦æƒ…
            movie_data = []
            for link in movie_links:
                try:
                    detail_response = self.network_manager.get_page(link, use_selenium=True)
                    movie_info = self.parser.parse_movie_detail(detail_response, link)
                    if movie_info:
                        movie_data.append(movie_info)
                except Exception as e:
                    self.logger.warning(f"è·å–æœç´¢ç»“æœè¯¦æƒ…å¤±è´¥: {link}, {e}")
                    continue
            
            return self.data_processor.clean_movie_data(movie_data)
            
        except Exception as e:
            self.logger.error(f"æœç´¢IMDBç”µå½±å¤±è´¥: {e}")
            return []
    
    def get_movies_by_genre(self, genre, max_movies=50):
        """æ ¹æ®ç±»å‹è·å–ç”µå½±"""
        try:
            urls = self.config.get_genre_url(genre)
            # ä½¿ç”¨æ–°çš„ä¸¤é˜¶æ®µæ–¹æ³•
            movie_links = self._collect_sufficient_links([genre], max_movies, max_pages=3)
            
            if len(movie_links) > max_movies:
                movie_links = random.sample(movie_links, max_movies)
            
            raw_data = self._crawl_movie_details_with_limit(movie_links, max_movies)
            return self.data_processor.clean_movie_data(raw_data)
            
        except Exception as e:
            self.logger.error(f"æ ¹æ®ç±»å‹è·å–ç”µå½±å¤±è´¥: {e}")
            return []
    
    def get_supported_categories(self):
        """
        è·å–æ”¯æŒçš„åˆ†ç±»åˆ—è¡¨
        
        Returns:
            dict: åˆ†ç±»å­—å…¸ï¼Œé”®ä¸ºåˆ†ç±»ä»£ç ï¼Œå€¼ä¸ºåˆ†ç±»åç§°
        """
        return self.config.CRAWL_CATEGORIES.copy()
    
    def test_connection(self):
        """
        æµ‹è¯•ç½‘ç»œè¿æ¥
        
        Returns:
            bool: è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            response = self.network_manager.get_page(self.config.BASE_URL, use_selenium=True)
            return response is not None
        except Exception as e:
            self.logger.error(f"IMDBè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿›å…¥"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        self.network_manager.close()
