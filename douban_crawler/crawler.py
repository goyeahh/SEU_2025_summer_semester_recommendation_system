#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¸»çˆ¬è™«ç±»
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€çš„çˆ¬è™«æ¥å£
"""

import os
import logging
from tqdm import tqdm
import random
import time

from .config import Config
from .network import NetworkManager
from .parser import PageParser
from .data_processor import DataProcessor


class DoubanMovieCrawler:
    """è±†ç“£ç”µå½±çˆ¬è™«ä¸»ç±»"""
    
    def __init__(self, config=None):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.config = config or Config()
        self.network_manager = NetworkManager()
        self.parser = PageParser()
        self.data_processor = DataProcessor()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if not os.path.exists(self.config.OUTPUT_DIR):
            os.makedirs(self.config.OUTPUT_DIR)
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        self.logger.info("è±†ç“£ç”µå½±çˆ¬è™«åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        log_config = self.config.LOG_CONFIG
        logging.basicConfig(
            level=getattr(logging, log_config['level']),
            format=log_config['format'],
            handlers=[
                logging.FileHandler(log_config['file'], encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def crawl_movies(self, categories=None, max_movies=None, max_pages=10):
        """
        åˆ†æ‰¹çˆ¬å–ç”µå½±æ•°æ® - æ”¶é›†ä¸€æ‰¹é“¾æ¥ï¼Œè§£æå®Œæ¯•åå†æ”¶é›†ä¸‹ä¸€æ‰¹
        
        Args:
            categories: è¦çˆ¬å–çš„åˆ†ç±»åˆ—è¡¨ï¼Œé»˜è®¤['hot']
            max_movies: æœ€å¤§çˆ¬å–ç”µå½±æ•°é‡ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®å€¼
            max_pages: æ¯ä¸ªåˆ†ç±»æœ€å¤§é¡µæ•°ï¼Œé»˜è®¤10
            
        Returns:
            dict: çˆ¬å–ç»“æœä¿¡æ¯
        """
        categories = categories or ['hot']
        max_movies = max_movies or self.config.MAX_MOVIES
        
        self.logger.info(f"å¼€å§‹åˆ†æ‰¹çˆ¬å–è±†ç“£ç”µå½±æ•°æ® - åˆ†ç±»: {categories}, ç›®æ ‡æ•°é‡: {max_movies}")
        
        try:
            all_movie_data = []
            collected_links = set()  # é¿å…é‡å¤é“¾æ¥
            batch_size = 50  # æ¯æ‰¹æ”¶é›†50ä¸ªé“¾æ¥
            batch_count = 0
            
            while len(all_movie_data) < max_movies:
                batch_count += 1
                remaining = max_movies - len(all_movie_data)
                target_batch_links = min(batch_size, remaining * 2)  # æ¯æ‰¹æ”¶é›†çš„é“¾æ¥æ•°
                
                self.logger.info(f"=== ç¬¬ {batch_count} æ‰¹çˆ¬å– ===")
                self.logger.info(f"å·²è·å–: {len(all_movie_data)} éƒ¨ç”µå½±ï¼Œè¿˜éœ€: {remaining} éƒ¨")
                
                # é˜¶æ®µ1ï¼šæ”¶é›†ä¸€æ‰¹æ–°çš„ç”µå½±é“¾æ¥ï¼ˆä¸é‡å¤ï¼‰
                self.logger.info(f"é˜¶æ®µ1: æ”¶é›† {target_batch_links} ä¸ªè±†ç“£ç”µå½±é“¾æ¥...")
                new_links = self._collect_batch_links(categories, target_batch_links, collected_links, max_pages)
                
                if not new_links:
                    self.logger.warning("æ— æ³•æ”¶é›†åˆ°æ›´å¤šè±†ç“£ç”µå½±é“¾æ¥ï¼Œçˆ¬å–ç»“æŸ")
                    break
                
                collected_links.update(new_links)
                self.logger.info(f"âœ“ é“¾æ¥æ”¶é›†å®Œæˆï¼æœ¬æ‰¹æ”¶é›† {len(new_links)} ä¸ªæ–°é“¾æ¥")
                
                # é˜¶æ®µ2ï¼šå®Œå…¨è§£æè¿™æ‰¹ç”µå½±ï¼ˆç›´åˆ°å®Œæˆæˆ–å¤±è´¥ï¼‰
                self.logger.info(f"é˜¶æ®µ2: å¼€å§‹è§£ææœ¬æ‰¹ {len(new_links)} ä¸ªè±†ç“£ç”µå½±...")
                batch_movies = self._parse_batch_movies(list(new_links), remaining)
                
                if batch_movies:
                    all_movie_data.extend(batch_movies)
                    self.logger.info(f"âœ“ æœ¬æ‰¹è§£æå®Œæˆï¼è·å– {len(batch_movies)} éƒ¨ç”µå½±ï¼Œæ€»è®¡: {len(all_movie_data)}/{max_movies}")
                else:
                    self.logger.warning(f"âœ— æœ¬æ‰¹é“¾æ¥è§£æå¤±è´¥ï¼Œè·³è¿‡ç»§ç»­ä¸‹ä¸€æ‰¹")
                
                # å¦‚æœå·²è¾¾åˆ°ç›®æ ‡ï¼Œåœæ­¢
                if len(all_movie_data) >= max_movies:
                    self.logger.info(f"ğŸ‰ å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {max_movies}ï¼Œçˆ¬å–ä»»åŠ¡å®Œæˆï¼")
                    break
                
                # æ‰¹æ¬¡é—´ä¼‘æ¯
                self.logger.info("æ‰¹æ¬¡é—´ä¼‘æ¯ 5-10 ç§’...")
                time.sleep(random.uniform(5, 10))
            
            # æ•°æ®æ¸…æ´—å’Œæœ€ç»ˆä¿å­˜
            if all_movie_data:
                # é™åˆ¶åˆ°ç›®æ ‡æ•°é‡
                final_movies = all_movie_data[:max_movies]
                cleaned_data = self.data_processor.clean_movie_data(final_movies)
                saved_files = self.data_processor.save_processed_data(
                    cleaned_data, 
                    self.config.OUTPUT_DIR
                )
                
                self.logger.info(f"è±†ç“£çˆ¬è™«ä»»åŠ¡å®Œæˆï¼æœ€ç»ˆè·å– {len(cleaned_data)} éƒ¨ç”µå½±ä¿¡æ¯")
                
                return {
                    'success': True,
                    'data_count': len(cleaned_data),
                    'file_paths': saved_files,
                    'message': f'æˆåŠŸçˆ¬å– {len(cleaned_data)} éƒ¨è±†ç“£ç”µå½±'
                }
            else:
                return {
                    'success': False,
                    'data_count': 0,
                    'file_paths': {},
                    'message': 'æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆè±†ç“£ç”µå½±æ•°æ®'
                }
            
        except Exception as e:
            self.logger.error(f"è±†ç“£çˆ¬è™«è¿è¡Œå‡ºé”™: {e}")
            return {
                'success': False,
                'data_count': 0,
                'file_paths': {},
                'message': f'è±†ç“£çˆ¬å–å¤±è´¥: {str(e)}'
            }
        finally:
            self.network_manager.close()
    
    def _collect_batch_links(self, categories, target_count, exclude_links, max_pages):
        """æ”¶é›†ä¸€æ‰¹æ–°çš„ç”µå½±é“¾æ¥ï¼ˆé¿å…é‡å¤ï¼‰"""
        new_links = []
        
        for category in categories:
            if len(new_links) >= target_count:
                break
            
            self.logger.info(f"ä»åˆ†ç±» '{category}' æ”¶é›†é“¾æ¥...")
            category_urls = self.config.get_movie_list_urls([category], max_pages)
            
            for i, url in enumerate(tqdm(category_urls, desc=f"è§£æ{category}åˆ—è¡¨é¡µ", leave=False)):
                if len(new_links) >= target_count:
                    self.logger.info(f"å·²æ”¶é›†è¶³å¤Ÿé“¾æ¥ ({len(new_links)}ä¸ª)ï¼Œåœæ­¢æ­¤åˆ†ç±»")
                    break
                
                try:
                    # å»¶æ—¶
                    if i > 0:
                        time.sleep(random.uniform(2, 4))
                    
                    # è·å–é¡µé¢å†…å®¹
                    response = self.network_manager.get_page(url, use_selenium=False)
                    
                    # è§£æç”µå½±é“¾æ¥
                    movie_links = self.parser.parse_movie_list(response)
                    
                    if not movie_links:
                        # å°è¯•Selenium
                        self.logger.info(f"requestsæœªè·å–åˆ°é“¾æ¥ï¼Œå°è¯•Selenium: {url}")
                        response = self.network_manager.get_page(url, use_selenium=True)
                        movie_links = self.parser.parse_movie_list(response)
                    
                    # è¿‡æ»¤å·²æ”¶é›†çš„é“¾æ¥
                    filtered_links = [link for link in movie_links if link not in exclude_links]
                    new_links.extend(filtered_links)
                    
                    if filtered_links:
                        self.logger.info(f"ä»é¡µé¢è·å– {len(filtered_links)} ä¸ªæ–°é“¾æ¥ï¼Œç´¯è®¡: {len(new_links)}")
                    
                except Exception as e:
                    self.logger.warning(f"è§£æåˆ—è¡¨é¡µé¢å¤±è´¥: {url}, é”™è¯¯: {e}")
                    continue
        
        # å»é‡å¹¶è¿”å›éœ€è¦çš„æ•°é‡
        unique_links = list(set(new_links))[:target_count]
        self.logger.info(f"æ‰¹æ¬¡é“¾æ¥æ”¶é›†å®Œæˆ - è·å¾— {len(unique_links)} ä¸ªæ–°é“¾æ¥")
        return unique_links
    
    def _parse_batch_movies(self, movie_links, max_count):
        """è§£æä¸€æ‰¹ç”µå½±è¯¦æƒ…"""
        self.logger.info(f"å¼€å§‹è§£æ {len(movie_links)} ä¸ªç”µå½±è¯¦æƒ…ï¼ˆæœ€å¤š {max_count} éƒ¨ï¼‰")
        movie_data = []
        
        for i, link in enumerate(tqdm(movie_links, desc="è§£æç”µå½±è¯¦æƒ…", leave=False)):
            if len(movie_data) >= max_count:
                self.logger.info(f"å·²è¾¾åˆ°æ‰¹æ¬¡ç›®æ ‡ {max_count}ï¼Œåœæ­¢è§£æ")
                break
            
            try:
                # å»¶æ—¶
                time.sleep(random.uniform(
                    self.config.DELAY_MIN,
                    self.config.DELAY_MAX
                ))
                
                # é¦–å…ˆå°è¯•requests
                response = self.network_manager.get_page(link, use_selenium=False)
                movie_info = self.parser.parse_movie_detail(response, link)
                
                # å¦‚æœæ•°æ®ä¸å®Œæ•´ï¼Œå°è¯•Selenium
                if not movie_info or not self._is_movie_info_complete(movie_info):
                    self.logger.info(f"requestsæ•°æ®ä¸å®Œæ•´ï¼Œä½¿ç”¨Seleniumé‡è¯•: {link}")
                    response = self.network_manager.get_page(link, use_selenium=True)
                    movie_info = self.parser.parse_movie_detail(response, link)
                
                if movie_info and movie_info.get('title'):
                    movie_data.append(movie_info)
                    self.logger.info(f"âœ“ è§£ææˆåŠŸ: {movie_info.get('title')} ({len(movie_data)}/{max_count})")
                
            except Exception as e:
                self.logger.warning(f"âœ— è§£æç”µå½±è¯¦æƒ…å¤±è´¥: {link}, é”™è¯¯: {e}")
                continue
        
        self.logger.info(f"æ‰¹æ¬¡è§£æå®Œæˆ - æˆåŠŸè·å– {len(movie_data)} éƒ¨ç”µå½±")
        return movie_data

    def _collect_sufficient_links(self, categories, target_count, max_pages):
        all_movie_links = []
        
        for category in categories:
            if len(all_movie_links) >= target_count * 2:  # æ”¶é›†è¶³å¤Ÿçš„é“¾æ¥ååœæ­¢
                self.logger.info(f"å·²æ”¶é›†è¶³å¤Ÿé“¾æ¥ ({len(all_movie_links)}ä¸ª)ï¼Œåœæ­¢è§£æåˆ—è¡¨é¡µé¢")
                break
            
            self.logger.info(f"å¼€å§‹æ”¶é›†åˆ†ç±» '{category}' çš„ç”µå½±é“¾æ¥")
            category_urls = self.config.get_movie_list_urls([category], max_pages)
            
            for i, url in enumerate(tqdm(category_urls, desc=f"è§£æ{category}åˆ—è¡¨é¡µ")):
                if len(all_movie_links) >= target_count * 2:  # è¾¾åˆ°ç›®æ ‡åç«‹å³åœæ­¢
                    self.logger.info(f"å·²æ”¶é›†åˆ° {len(all_movie_links)} ä¸ªé“¾æ¥ï¼Œåœæ­¢è§£ææ›´å¤šåˆ—è¡¨é¡µ")
                    break
                
                try:
                    # æ·»åŠ å»¶æ—¶
                    if i > 0:
                        time.sleep(random.uniform(
                            self.config.DELAY_MIN,
                            self.config.DELAY_MAX
                        ))
                    
                    # ä½¿ç”¨Seleniumè·å–é¡µé¢
                    response = self.network_manager.get_page(url, force_selenium=True)
                    
                    # ç¡®å®šURLç±»å‹
                    url_type = 'typerank' if 'typerank' in url else 'chart'
                    
                    # è§£æç”µå½±é“¾æ¥
                    movie_links = self.parser.parse_movie_list(response, url_type)
                    
                    if len(movie_links) > 0:
                        all_movie_links.extend(movie_links)
                        self.logger.info(f"ä»é¡µé¢è·å– {len(movie_links)} ä¸ªé“¾æ¥ï¼Œæ€»è®¡: {len(all_movie_links)}")
                    else:
                        self.logger.warning(f"é¡µé¢æ— é“¾æ¥ï¼Œå¯èƒ½è¢«åçˆ¬è™«æ‹¦æˆª: {url}")
                        # å¦‚æœè¿ç»­å¤±è´¥ï¼Œå¢åŠ å»¶æ—¶
                        time.sleep(random.uniform(5, 10))
                
                except Exception as e:
                    self.logger.warning(f"è§£æåˆ—è¡¨é¡µé¢å¤±è´¥: {url}, é”™è¯¯: {e}")
                    continue
        
        # å»é‡
        unique_links = list(set(all_movie_links))
        self.logger.info(f"æ”¶é›†é˜¶æ®µå®Œæˆ - æ€»é“¾æ¥æ•°: {len(unique_links)}")
        
        return unique_links
    
    def _crawl_movie_details_with_limit(self, movie_links, max_movies):
        """çˆ¬å–ç”µå½±è¯¦æƒ…ï¼ˆå¸¦æ•°é‡é™åˆ¶ï¼‰"""
        movie_data = []
        
        for i, link in enumerate(tqdm(movie_links, desc="çˆ¬å–ç”µå½±è¯¦æƒ…")):
            if len(movie_data) >= max_movies:
                self.logger.info(f"å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {max_movies}ï¼Œåœæ­¢çˆ¬å–è¯¦æƒ…")
                break
            
            try:
                # è¯¦æƒ…é¡µå»¶æ—¶
                time.sleep(random.uniform(
                    self.config.DELAY_MIN,
                    self.config.DELAY_MAX
                ))
                
                # çˆ¬å–è¯¦æƒ…
                response = self.network_manager.get_page(link)
                movie_info = self.parser.parse_movie_detail(response, link)
                
                if movie_info and movie_info.get('title'):
                    movie_data.append(movie_info)
                    self.logger.info(f"æˆåŠŸçˆ¬å–: {movie_info.get('title')} ({len(movie_data)}/{max_movies})")
                else:
                    self.logger.warning(f"ç”µå½±ä¿¡æ¯è§£æå¤±è´¥: {link}")
                
            except Exception as e:
                self.logger.warning(f"çˆ¬å–ç”µå½±è¯¦æƒ…å¤±è´¥: {link}, é”™è¯¯: {e}")
                continue
        
        self.logger.info(f"è¯¦æƒ…çˆ¬å–å®Œæˆ - æˆåŠŸè·å– {len(movie_data)} éƒ¨ç”µå½±")
        return movie_data
    
    def _collect_movie_links(self, list_urls):
        """æ”¶é›†ç”µå½±è¯¦æƒ…é¡µé“¾æ¥ - å¢å¼ºç‰ˆ"""
        all_movie_links = []
        failed_pages = 0
        max_consecutive_fails = 3  # æœ€å¤§è¿ç»­å¤±è´¥æ¬¡æ•°
        consecutive_fails = 0
        
        for i, url in enumerate(tqdm(list_urls, desc="è§£æç”µå½±åˆ—è¡¨é¡µé¢")):
            try:
                # åŠ¨æ€è°ƒæ•´å»¶æ—¶
                if consecutive_fails > 0:
                    delay = random.uniform(
                        self.config.DELAY_MIN * (1 + consecutive_fails), 
                        self.config.DELAY_MAX * (1 + consecutive_fails)
                    )
                    time.sleep(delay)
                else:
                    time.sleep(random.uniform(
                        self.config.DELAY_MIN, 
                        self.config.DELAY_MAX
                    ))
                
                # æ™ºèƒ½è¯·æ±‚ç­–ç•¥
                use_selenium = consecutive_fails >= 2  # è¿ç»­å¤±è´¥2æ¬¡åä½¿ç”¨Selenium
                response = self.network_manager.get_page(url, force_selenium=use_selenium)
                
                # ç¡®å®šURLç±»å‹
                url_type = 'typerank' if 'typerank' in url else 'chart'
                
                movie_links = self.parser.parse_movie_list(response, url_type)
                
                if len(movie_links) == 0:
                    consecutive_fails += 1
                    failed_pages += 1
                    self.logger.warning(f"é¡µé¢ {i+1}/{len(list_urls)} è§£æå¤±è´¥: {url}")
                    
                    # å¦‚æœè¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œå¯èƒ½é‡åˆ°äº†åçˆ¬è™«
                    if consecutive_fails >= max_consecutive_fails:
                        self.logger.error(f"è¿ç»­{max_consecutive_fails}é¡µè§£æå¤±è´¥ï¼Œå¯èƒ½é‡åˆ°åçˆ¬è™«é™åˆ¶")
                        # å¢åŠ æ›´é•¿çš„å»¶æ—¶
                        time.sleep(random.uniform(10, 20))
                        consecutive_fails = 0  # é‡ç½®è®¡æ•°å™¨
                else:
                    all_movie_links.extend(movie_links)
                    consecutive_fails = 0  # æˆåŠŸåé‡ç½®å¤±è´¥è®¡æ•°
                    self.logger.info(f"é¡µé¢ {i+1}/{len(list_urls)} æˆåŠŸè·å– {len(movie_links)} ä¸ªé“¾æ¥")
                
            except Exception as e:
                failed_pages += 1
                consecutive_fails += 1
                self.logger.warning(f"è§£æåˆ—è¡¨é¡µé¢å¤±è´¥: {url}, é”™è¯¯: {e}")
                
                # å¤±è´¥æ—¶å¢åŠ å»¶æ—¶
                time.sleep(random.uniform(5, 10))
                continue
        
        # å»é‡
        unique_links = list(set(all_movie_links))
        success_rate = (len(list_urls) - failed_pages) / len(list_urls) * 100
        
        self.logger.info(f"æ”¶é›†å®Œæˆ - æˆåŠŸç‡: {success_rate:.1f}%, æ€»é“¾æ¥æ•°: {len(unique_links)}, å¤±è´¥é¡µé¢: {failed_pages}")
        
        return unique_links
    
    def _stream_crawl_category(self, category_urls, category_name, max_movies):
        """
        æµå¼çˆ¬å–åˆ†ç±»ç”µå½± - è¾¹è§£æè¾¹çˆ¬å–
        
        Args:
            category_urls: è¯¥åˆ†ç±»çš„åˆ—è¡¨é¡µURLs
            category_name: åˆ†ç±»åç§°
            max_movies: è¯¥åˆ†ç±»æœ€å¤§ç”µå½±æ•°é‡
            
        Returns:
            list: çˆ¬å–åˆ°çš„ç”µå½±æ•°æ®
        """
        collected_movies = []
        processed_urls = 0
        
        for url in tqdm(category_urls, desc=f"å¤„ç†{category_name}åˆ†ç±»"):
            if len(collected_movies) >= max_movies:
                self.logger.info(f"åˆ†ç±» {category_name} å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {max_movies}")
                break
            
            try:
                # æ·»åŠ éšæœºå»¶æ—¶ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                if processed_urls > 0:
                    delay = random.uniform(
                        self.config.DELAY_MIN * 2,  # å¢åŠ å»¶æ—¶
                        self.config.DELAY_MAX * 2
                    )
                    time.sleep(delay)
                
                # è·å–åˆ—è¡¨é¡µ
                response = self.network_manager.get_page(url, force_selenium=True)  # ä¼˜å…ˆä½¿ç”¨Selenium
                
                # ç¡®å®šURLç±»å‹
                url_type = 'typerank' if 'typerank' in url else 'chart'
                
                # è§£æç”µå½±é“¾æ¥
                movie_links = self.parser.parse_movie_list(response, url_type)
                
                if len(movie_links) == 0:
                    self.logger.warning(f"åˆ—è¡¨é¡µé¢æ— ç”µå½±é“¾æ¥: {url}")
                    processed_urls += 1
                    continue
                
                # ç«‹å³çˆ¬å–è¿™æ‰¹ç”µå½±çš„è¯¦æƒ…
                for link in movie_links:
                    if len(collected_movies) >= max_movies:
                        break
                    
                    try:
                        # éšæœºå»¶æ—¶
                        time.sleep(random.uniform(
                            self.config.DELAY_MIN,
                            self.config.DELAY_MAX
                        ))
                        
                        # çˆ¬å–è¯¦æƒ…
                        detail_response = self.network_manager.get_page(link)
                        movie_info = self.parser.parse_movie_detail(detail_response, link)
                        
                        if movie_info and movie_info.get('title'):  # åŸºæœ¬éªŒè¯
                            collected_movies.append(movie_info)
                            self.logger.info(f"æˆåŠŸçˆ¬å–: {movie_info.get('title')} ({len(collected_movies)}/{max_movies})")
                        
                    except Exception as e:
                        self.logger.warning(f"çˆ¬å–ç”µå½±è¯¦æƒ…å¤±è´¥: {link}, é”™è¯¯: {e}")
                        continue
                
                processed_urls += 1
                
            except Exception as e:
                self.logger.warning(f"å¤„ç†åˆ—è¡¨é¡µé¢å¤±è´¥: {url}, é”™è¯¯: {e}")
                processed_urls += 1
                continue
        
        return collected_movies

    def _crawl_movie_details(self, movie_links):
        """çˆ¬å–ç”µå½±è¯¦æƒ…"""
        movie_data = []
        
        for link in tqdm(movie_links, desc="çˆ¬å–ç”µå½±è¯¦æƒ…"):
            try:
                response = self.network_manager.get_page(link)
                movie_info = self.parser.parse_movie_detail(response, link)
                
                if movie_info:
                    movie_data.append(movie_info)
                
                # éšæœºå»¶æ—¶é¿å…è¢«å°
                time.sleep(random.uniform(
                    self.config.DELAY_MIN, 
                    self.config.DELAY_MAX
                ))
                
            except Exception as e:
                self.logger.warning(f"çˆ¬å–ç”µå½±è¯¦æƒ…å¤±è´¥: {link}, é”™è¯¯: {e}")
                continue
        
        self.logger.info(f"æˆåŠŸçˆ¬å– {len(movie_data)} éƒ¨ç”µå½±è¯¦æƒ…")
        return movie_data
    
    def get_movie_by_id(self, douban_id):
        """æ ¹æ®è±†ç“£IDè·å–å•ä¸ªç”µå½±ä¿¡æ¯"""
        url = f"{self.config.BASE_URL}/subject/{douban_id}/"
        
        try:
            response = self.network_manager.get_page(url)
            movie_info = self.parser.parse_movie_detail(response, url)
            
            if movie_info:
                cleaned_data = self.data_processor.clean_movie_data([movie_info])
                return cleaned_data[0] if cleaned_data else None
            
        except Exception as e:
            self.logger.error(f"è·å–ç”µå½±ä¿¡æ¯å¤±è´¥ (ID: {douban_id}): {e}")
            
        return None
    
    def search_movies(self, keyword, max_results=20):
        """æœç´¢ç”µå½±ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        # æ³¨æ„ï¼šè±†ç“£çš„æœç´¢å¯èƒ½éœ€è¦æ›´å¤æ‚çš„å¤„ç†
        search_url = f"{self.config.BASE_URL}/search?q={keyword}"
        
        try:
            response = self.network_manager.get_page(search_url)
            # è¿™é‡Œéœ€è¦å®ç°æœç´¢ç»“æœé¡µé¢çš„è§£æ
            # ç”±äºè±†ç“£æœç´¢é¡µé¢ç»“æ„å¤æ‚ï¼Œè¿™é‡Œå…ˆè¿”å›ç©ºåˆ—è¡¨
            self.logger.warning("æœç´¢åŠŸèƒ½éœ€è¦è¿›ä¸€æ­¥å®ç°")
            return []
            
        except Exception as e:
            self.logger.error(f"æœç´¢ç”µå½±å¤±è´¥: {e}")
            return []
    
    def get_supported_categories(self):
        """
        è·å–æ”¯æŒçš„åˆ†ç±»åˆ—è¡¨
        
        Returns:
            dict: åˆ†ç±»å­—å…¸ï¼Œé”®ä¸ºåˆ†ç±»ä»£ç ï¼Œå€¼ä¸ºåˆ†ç±»åç§°
        """
        return self.config.CRAWL_CATEGORIES.copy()
    
    def test_connection(self):
        """
        æµ‹è¯•ç½‘ç»œè¿æ¥
        
        Returns:
            bool: è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            response = self.network_manager.get_page(self.config.BASE_URL)
            return response is not None
        except Exception as e:
            self.logger.error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿›å…¥"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        self.network_manager.close()
